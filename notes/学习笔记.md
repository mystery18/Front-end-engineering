# 脚手架工具

## 概要

脚手架可以简单理解为自动帮我们创建项目基础文件的一个工具，更重要的是提供给开发者一些约定和规范。可以通过脚手架工具去快速搭建特定类型的项目骨架，然后去基于这个骨架进行后续的开发工作。

由于前端技术选型比较多样，也没有一个统一的标准，所以前端方向的脚手架一般不会集成在某一个IDE当中，都是以一个独立的工具存在，而且相对会复杂一些，但本质上脚手架的目标都是一样的，因为他们都是为了解决我们在创建项目过程中那些复杂工作。

- 脚手架作用
- 常用的脚手架工具
- 通用脚手架工具剖析
- 开发一款脚手架

## Yeoman简介

vue-cli、angular-cli等这类的工具太过于针对某一个框架，而且在使用上也非常普及，这就不做过多的介绍，着重探讨Yeoman工具。官方的定义是用于创造现代化web应用的脚手架工具，不同于vue-cli这类工具，yeoman更像是脚手架的运行平台。其优点也是它的缺点，在很多专注基于框架开发的人眼中，yeoman它过于通用 不够专注，所以他们更愿意使用vue-cli这类工具。

### 基本使用

它是一款基于node.js开发的工具模块，使用yeoman第一步自然是`yarn global add yo`，单有yo这个模块不够，因为yeoman是搭配特定的generator去使用，需要找到对应项目的generator，`yarn global add generator-node`安装一下，就可以使用yarn运行生成器自动去帮我们创建一个全新的node_modules。

切换对应目录后，mkdir + 文件名 来创建一个新的文件夹，通过命令`yo node`去运行刚刚所安装的generator-node的生成器，在这个过程中yeoman会提一些问题，模块名、already exist选yes、no、description、主页等等等。当所有选项都输入完成后，会在咱们当前目录下创建一些基础文件，并且帮我们在项目根目录下运行npm install去安装这个项目必要的一些依赖。

脚手架工作流程的主要目的就是让我们**<u>得到一个基础的项目结构以及一些基础的项目代码</u>**。

- 在全局范围安装yo

  ```bash
  npm install yo --global  # or yarn global add yo
  ```

- 安装对应的generator

  ```bash
  npm install generator-node --global # or yarn global add generator-node
  ```

- 通过yo运行generator

  ```bash
  cd path/to/project-dir
  mkdir my-module
  yo node
  ```



### Sub Generator

有时候我们不需要去创建完整的项目结构，只是需要在已有的项目基础上去创建一些特定类型的文件，例如给已经存在的项目创建readme.md或是一些配置文件如ESlint或babel配置文件 都有一些基础代码，如果手动去写很容易配错，可以通过生成器自动帮我们生成，这样会提高效率。如果是需要这样的需求的话，可以使用yeoman所提供的Sub Generator特性来实现。

```bash
yo node:cli
```

是否重写package.json（yes），完成后创建了个新的文件cli.js。有了这些就可以将我们这个模块做一个全局的命令行模块去使用了，本地的模块可以通过`yarn link`到全局范围，link到全局范围后就可以通过模块的名字（`my-module --help`）去运行刚刚所加进来的模块，如果报错就运行`yarn` 来把依赖项里的模块都安装进来，再来运行`my-module --help`命令，此时cli应用就正常工作了，这就是generator的子集的特性。

值得注意的是，并不是每一个generator都提供子集生成器，所以我们在使用之前需要通过你所使用的generator的官方文档来去明确这个generator下面有没有一个子集的生成器。

### 使用步骤总结

1. 明确你的需求
2. 找到合适的Generator
3. 全局范围安装找到Generator
4. 通过Yo运行对应的Generator
5. 通过命令行交互填写选项
6. 生成你所需要的项目结构

如：

```bash
yarn global add generator-webapp
yo webapp
```



### 自定义 Generator

不同的generator可以生成不同的项目，那我们可以通过创造自己的generator去帮我们生成自定义的项目结构。



### 创建 Generator 模块

创建Generator实际上就是创建一个npm模块（Generator本质上就是一个npm模块），但是Generator他有特定结构，需要在根目录下有generators文件夹，然后在这个文件夹下面建app文件夹用于存生成器对应的代码，下面存 index.js。如果需要提供多个sub Generator，可以在app同级目录下添加一个新的生成器目录，如component及下index.js 此时我们模块就有一个叫 component 的子生成器。

除了特定的结构，还有一个与普通npm不同的是yeoman的Generator模块名称必须是 generator-<name> 的格式，如果说在具体开发的时候没有使用这种格式的名称，yeoman就会在后续工作的时候没有办法找到你所提供的这种生成器模块。

```bash
mkdir generator-sample
cd generator-sample
yarn init # 创建package.json

yarn add yeoman-generator # 安装一个yeoman-generator模块，提供了生成器的基类 提供了一些工具函数，让我们可以在创建生成器的时候更加便捷。安装完后通过VScode打开：code .
```

在目录下创建一个generators文件夹，再创建一个app目录 再在下面创index.js文件。

```js
// index.js

// 这个文件会作为generator的核心入口，它需要导出一个继承自yeoman generator 类型
// yeoman generator 在工作时会自动调用我们在此类型中定义的一些声明周期方法
// 可以在这些方法中通过调用父类提供的一些工具方法实现一些功能，例如文件写入

const Generator = require('yeoman-generator')

// 需要导出这个类型，让这个类型继承自Generator
module.exports = class extends Generator {
    // 在这个类型需要定义一个writing方法，这个方法在yeoman工作的时候 他会在生成文件阶段自动调用这个类型中的writing方法
	writing (){
        // 在这个方法可以通过文件读写的方式往我们生成的目录下去写入文件
        // 这里的fs模块与node的fs模块不一样的，这里的是高度封装的filesystem模块，相对于原生fs模块功能更强大些
        
        // write方法有两个参数。1、写入文件的绝对路径；2、写入文件的内容
        this.fs.write(
            // 借助父类的方法去自动获取生成项目目录下对应的文件路径
            this.destinationPath('temp.txt'),
            
            //文件的内容用生成随机数代替
            Math.random().toSrting()
        )
    }
}
```

回到命令行用`yarn link`链接到全局范围，使之成为全局模块包，这样yeoman在工作的时候就可以找到我们自己写的generator-sample了。

cd ..到上级，新建一个文件夹（`mkdir mypj`）然后 cd进去，通过`yo sample`后，提示我们创建了temp.txt文件。



### 根据模板创建文件

很多时候我们需要自动创建的文件有很多，而且文件内容也相对复杂，在这种情况下可以使用模板去创建文件，这样可以更加便捷一些。首先在生成器目录下添加templates目录（在app目录下），将我们需要去生成的文件都放入templates目录作为模板。模板中是完全遵循EJS模板引擎的模板语法，即我们可以通过 `<%= title %>` 动态输出一些数据，也可以做一些判断、循环之类的操作。

有了模板过后，我们在生成文件时就不用再去借助于 fs 的 write 方法去写入文件，而是借助 fs当中有一个专门使用模板引擎的方法，叫做 copy-template 的方式，具体使用他有3个参数：1、模板文件路径；2、输出文件路径；3、模板数据的上下文。

模板文件路径可以借助于 templatePath 方法自动获取当前生成器下 templates 下面的文件路径；输出路径我们还是使用 destination path；在模板数据上下文这只需要去定义一个对象就可以了。将这3个参数通过 copyTpl 方法传入，这个方法会自动去把我们模板文件映射到生成的输出文件上。然后回到命令行再次通过 yeoman 去运行我们这个 generator（`yo sample`），此时 yeoman的运行过程中就会自动使用模板引擎去渲染模板，将渲染过后的结果，放到我们的输出目录。

```js
const Generator = require('yeoman-generator')

module.exports = class extends Generator {

    writing() {
        // 有了模板过后，我们在生成文件时就不用再去借助于fs的write方法去写入文件。
        // 通过模板方式写入文件到目标目录

        // 模板文件路径
        const templ = this.templatePath('foo.txt')
        // 输出目标路径
        const output = this.destinationPath('foo.txt')
        // 模板数据上下文
        const context = { title: 'Hello yy~', success: false }
        this.fs.copyTpl(templ, output, context)
    }
}
```

那么相对于手动创建每一个文件，模板的方式大大提高了效率，特别是在文件比较多，比较复杂情况下。



### 接收用户输入

对于模板中的动态数据，如项目标题、项目名称，这样的数据我们一般通过命令行交互的方式去询问我们的使用者从而得到，那在generator 中想要发起一个命令行交互的询问，可以通过实现 generator 这个类型中的 prompting方法 （index.js里），这个方法中可以调用父类提供的 prompt() 发出对用户的命令行询问，这个方法返回一个promise，也就是说他是一个 promise 方法，即要在前面进行 return，这样的话 yeoman 在工作的时候就有更好的异步流程控制。

这个方法接收一个数组参数，数组的每一项都是一个问题对象，这个问题对象呢具体的可以去传入类型、name、还有 message 和 default，这里的 type 我们选用 input 也就是说使用用户输入的方式去接收用户提交信息，name 就是最终得到结果的一个键，然后 message 呢是在界面上给用户一个提示，也就是我们所谓的问题，那 default 呢我们这用的是一个叫 appname  的一个数据，这个属性实际上是父类当中自动帮我们拿到的当前生成项目的目录的文件夹名字，他会作为我们这个问题的默认值。

在这个 promise 执行完之后我们可以得到一个 answers ，这个answers 里面就是我们当前这个问题在接收完用户输入过后的一个结果，那他会以一个对象的形式出现，那对象里面的键就是我们刚刚 prompt 的 name，值就是用户输入的 value，将这个值挂载到 this 对象上面以便于我们后面在 writing 的时候去使用它。那有了 answers 数据过后就可以在 writing 的时候去传入我们的模板引擎，使用这个数据去作为模板数据的上下文。

回到 cmd 中再次运行`yo sample`，此时他会提示我们一个问题根据我们的需要输入，输入完的结果会作为数据出现在我们的数据上下文当中，最终在模板中被渲染出来。这个就是我们在 yeoman 中如何动态去接收用户输入数据的一种实现方式。

```js
const Generator = require('yeoman-generator')

module.exports = class extends Generator {
    prompting() {
        // Yeoman 在询问用户环节会自动调用此方法
        // 在此方法中可以调用父类的 prompt() 方法发出对用户的命令行询问
        return this.prompt([
            {
                type: 'input',
                name: 'name',
                message: 'Your project name',
                default: this.appname // appname 为项目生成目录名称
            }
        ])
            .then(answers => {
                // answers => { name: 'user input value' }
                this.answers = answers
            })
    }

    writing() {


        // 有了模板过后，我们在生成文件时就不用再去借助于fs的write方法去写入文件。
        // 通过模板方式写入文件到目标目录

        // 模板文件路径
        const templ = this.templatePath('foo.txt')
        // 输出目标路径
        const output = this.destinationPath('foo.txt')
        // 模板数据上下文
        const context = { title: 'Hello yy~', success: false }

        this.fs.copyTpl(templ, output, context)


    }
}
```

（再一次：哎这里真的要裂开了，不知道在讲什么，这部分先不记了。要炸了）

xxx，这个就是我们在yeoman中如何动态去接收用户输入数据的实现方式。。。。



### 发布 Generator

Generator实际上就是一个npm模块，所以说去发布Generator实际上就是发布一个npm模块，只需要将自己写好的Generator模块通过npm publish命令去发布成一个公开的模块就可以了





## Plop

小型脚手架工具，主要用于去创建项目中特定类型的文件的小工具，有点类似于 yeoman中 的 sub generator，一般不会独立去使用，一般会把 plop 去集成到项目中用来自动化创建同类型的项目文件。`yarn plop component`，帮我自动创建文件。

### plop基本使用

（<u>**这里用的是react项目作为案例。没有用过react搭建项目，这里就拿来做案例来讲解plop的基本使用。。。。什么template的完全听不懂，我是应该看完后面的react还是node 再来看这里？这里就先不记了 没有一个字看得懂，哎真的烦躁。**</u>）



## 脚手架的工作原理

就是在你启动它过后，他会自动去询问你一些预设的问题，将你回答的结果结合一些模板文件，生成一个项目的结构。现在通过node.js开发一个小型的脚手架工具，再来深入体会脚手架工具的工作过程。实际上是node cli应用，创建脚手架就是创建cli应用

（生成一个自定义的脚手架工具，根据命令行的输入来生成模板文件，通过文件写入的方式写入到目标目录， 等一系列配置过程）

<u>以后要回来看的话，从第四节课开始重新看，可能就看得懂了</u>

------

# 自动化构建

自动化实际指的就是通过机器去代替手工完成一些工作，构建可以理解成转换，就是把一个东西转换成另外一些东西。开发行业中的自动化构建就是把我们开发阶段写出来的源代码自动化去转换成生产环境中可以运行的代码或程序。这个过程称之为自动化构建工作流，作用就是让我们尽可能去脱离运行环境的种种问题，去在开发阶段使用一些提高效率的语法、规范和标准。

最典型的应用场景就是在开发网页应用时，可以使用ECMAScript最新标准提高编码效率和质量，利用Sass增强css的可编程性，借助模板引擎去抽象页面当中重复的HTML，那这些用法在浏览器中是没有办法直接被支持的，这种情况下，自动化构建工具可以派上用场。通过自动化构建的方式将这些不被支持的代码特性转换成能够直接运行的代码这样就可以尽情在开发过程中通过这些方式去提高编码的效率。



## 初体验 — NPM Scripts（体验较好）

Sass并不能在浏览器环境中直接使用，所以需要在开发阶段通过一个工具去把它转换成css，使用Sass官方提供的Sass模块，麻烦的是：每次都需要重复输入这些复杂的命令，而且在别人接手你的项目也不知道该如何运行这些构建的任务，需要解决需要重复执行的命令。

```bash
# 在生成package.json之后，作为开发依赖安装
yarn add sass --dev
# 在命令行通过路径找到这个命令 .\node_modules\.bin\sass
# 执行之后他会打印一些帮助信息，给出命令的具体用法（即需要指定一个sass的输入路径和css的输出路径）
.\node_modules\.bin\sass scss/main.scss css/style.css
# 再次执行完就会自动帮我们把sass文件转换成css，还帮我添加了对应的sourceMap文件，这样在我们调试阶段就可以定位到源代码中的位置
```



那NPM Scripts就是来解决这个问题，可以在npm scripts中去**<u>定义一些与这个项目开发过程有关的脚本命令，这样一来就可以让这些命令跟着项目一起去维护，便于我们在后期开发过程中的使用</u>**。所以最好的方式是通过npm scripts方式去包装你的构建命令。

**<u>实现方式</u>**：在package.json中添加scripts字段，这个字段是一个对象，键就是script的名称，值是我们需要执行的命令。需要注意的是，scripts它可以自动去发现node_modules里面的命令，所以我们就不需要写完整的路径，直接使用命令的名称就可以了。

```json
{
    "scripts": {
        "build": "sass scss/main.scss css/style.css"
    }
}
// 再通过npm或yarn去启动这个script：`yarn build`，而npm是 `npm run build`。
```



另外，NPM Scripts也是实现自动构建最简单的方式，再看一下如何通过它去实现自动化构建。这里为项目安装`browser-sync`模块，用于去**<u>启动一个测试服务器去运行我们的项目</u>**。

```bash
yarn add browser-sync --dev
```

此时我们去scripts中添加一个`serve`的命令，在这个命令中通过browser-sync把当前这个目录运行起来，回到命令行运行`yarn serve`命令。此时 browser-sync 会自动启动一个web服务器并帮我们唤起浏览器运行当前网页。

```json
{
    "scripts": {
        "build": "sass scss/main.scss css/style.css",
        "serve": "browser-sync ."
    }
}
```



但是如果在 browser-sync 工作之前，我们并没有生成我们的样式，此时 browser-sync 工作的时候，我们的页面就没有样式文件我们需要在启动serve命令之前去让build任务工作，所以我们这可以借助于NPM Scripts的钩子机制去定义一个preserve，它会自动在serve执行之前去执行，那这个时候你再去执行serve( `yarn serve` )，<u>它会自动化先执行build命令</u>，build完成 过后再去执行对应的serve，此时我们就可以完成在启动web服务之前，自动去构建我们的sass文件

```json
{
    "scripts": {
        "build": "sass scss/main.scss css/style.css",
        "preserve": "yarn build",
        "serve": "browser-sync ."
    }
}
```



此外，还可以为sass命令去添加一个刚刚watch参数，有了这个参数过后，sass在工作时就会监听文件的变化，一旦当我们sass文件发生改变就会自动被编译，此时回到命令行，重新运行之前的命令( `yarn serve` )，那你会发现sass命令在工作时，命令行会阻塞在这个地方去等待文件的变化，这样就导致了我们后面的 browser-sync 没有办法直接工作（不会唤起浏览器了），此时我们就需要同时去执行多个任务。

```json
{
    "scripts": {
        "build": "sass scss/main.scss css/style.css --watch",
        "preserve": "yarn build",
        "serve": "browser-sync ."
    }
}
```

这里可以借助 `yarn add npm-run-all --dev` <u>**这个模块**</u>去实现，需要先安装这个模块，有了这个模块就可以在scripts中再去添加一个新的命令，把这个命令叫start，在这个命令当中我们通过 npm-run-all 里面的run-p 命令，同时去执行build和serve命令。

```json
{
    "scripts": {
        "build": "sass scss/main.scss css/style.css --watch",
        "serve": "browser-sync .",
        "start": "run-p build serve"
    }
}
```

回到命令行中再去运行start命令（ `yarn start` ），此时你会发现build任务和browser-sync任务同时被执行了。尝试打开scss文件，去修改scss文件里面的内容，这个时候你会发现css文件也会跟着一起去变化，证明了我们的watch生效了。 



最后，我们还可以给 browser-sync 这个命令去添加一个 --files 的参数，这个参数可以让 browser-sync 在启动过后去监听项目下一些文件的变化，一旦文件发生变化过后，browser-sync 会将这些文件的内容自动同步到浏览器，从而更新浏览器中的界面，让我们可以及时查看到最新的界面效果，这样就**<u>避免了我们修改完代码过后，再去手动刷新浏览器的重复工作</u>**。

```json
{
    "scripts": {
        "build": "sass scss/main.scss css/style.css --watch",
        "serve": "browser-sync . --files \"css/*.css\"",
        "start": "run-p build serve"
    }
}
```

我们就借助了 npm scripts 完成了一个简单的自动化构建的工作流。它具体的工作流程就是在启动任务过后，同时去运行了 build 和serve 两个命令，其中 build 去自动监听 scss 文件的变化 去编译 scss， browser-sync 启动一个web服务，当文件发生变化过后去刷新浏览器。

------

## 常用的自动化构建工具

npm scripts 确实能解决一部分自动化构建任务，但是对于相对复杂的构建过程，npm scripts 就显得非常吃力，此时我们需要更为专业的构建工具。这里对市面上比较常用自动化构建工具去做一个大致的介绍，先有一个整体的认识，后面再做具体的深入探究。

目前市面上开发者使用最多的一些开发工具主要是 Gulp、Grunt、FIS。严格来说 webpack 是模块打包工具，所以说不在这次的讨论范围之内，这些工具都可以帮你解决那些重复而且无聊的工作，从而实现自动化，用法也大体相同，都是通过一些简单的代码去组织一些插件的使用，然后你就可以使用这些工具去帮你执行各种各样重复的工作了。

Grunt：算是最早的前端构建系统了，它的插件生态非常完善，用官方的一句话来说就是 Grunt 它的插件几乎可以帮你自动化完成任何你想要做的事情，但由于它的工作过程是基于临时文件去实现的，所以它的构建速度相对较慢，例如我们使用它去完成我们项目中 scss 文件的构建，那我们一般会对scss文件去做编译操作，再去自动添加一些私有属性的前缀，最后再去压缩代码，这样一个过程中，Grunt 每一步都会有磁盘读写操作，比如像 scss 文件在编译完成过后，就会将结果写入到一个临时的文件，然后下一个插件再去读取这个临时文件进行下一步，这样一来处理的环节越多，文件读写的次数也越多，那对于超大型项目当中，我们项目文件非常多，你的构建速度就会特别慢。

Gulp：而 Gulp 呢是我个人使用非常多的构建系统，它很好的解决了 Grunt 中构建速度非常慢的问题，因为它是基于内存去实现的，即它对文件处理环节都是在内存当中完成的，相对于磁盘读写，速度自然快很多。另外，它默认支持同时执行多个任务，效率自然大大提高，而且它的使用方式相对于 Grunt 更加直观易懂，插件生态也同样非常完善，所以说它后来居上，目前更受欢迎，应该算目前市面上最流行的前端构建系统了。

FIS：是百度前端团队推出的一款构建系统，最早只是在团队内部去使用，后来开元过后在国内快速流行，相对于前面两个构建系统，这种微内核的特点，FIS 更像是一种捆绑套餐，他把我们在项目中一些典型的需求尽可能集成在内部了，例如我们在FIS中就可以很轻松处理资源加载、模块化开发、代码部署，甚至是性能优化，正是因为这种大而全，所以在国内很多项目就流行开了。

总体来说：如果你是初学者，可能 FIS 更适合，但是如果你要求灵活多变的话，前面两个应该是你更好的选择。还是那句话，新手是需要规则的，而老手都会渴望自由，也正是因为这个原因，现在这些小而美的框架或工具才会得以流行。



------

## Grunt

### Grunt 的基本使用

首先需要 init 一个package.json，有了这个文件过后，需要通过 add 的方式去添加 grunt 模块。

```bash
npm init --yes # 写了--yes就不会那么多问题要回答了，或用 yarn init --yes
npm i grunt # yarn add grunt
code gruntfile.js
```

安装完之后还需要在这个项目的根目录下去添加一个 gruntfile 的文件，这个文件是 grunt 的入口文件，用于去定义一些需要 Grunt 自动执行的任务，我们在这个文件中需要导出一个函数，此函数去接收一个叫 grunt 的形参，grunt 是一个对象，对象中就是 grunt 提供的一些API，借助这些API去快速创建一些构建任务。

具体来做是通过 module.exports 去导出这个函数，在这个函数中借助于 grunt 的 registerTask 方法去注册一个任务，这个方法的第一个参数去指定一下这个任务的名字，第二个参数去指定一个任务函数，也就是当这个任务发生时自动去执行这个函数。然后回到命令行中运行命令：`yarn grunt foo` ，那 yarn 会自动去帮我们找 node_modules 中提供的一些命令，紧接着跟上 foo，即我们刚刚注册的任务名字，这样的话 grunt 就会自动帮我们去执行 foo 这个任务。

```js
module.exports = grunt => {
    grunt.registerTask('foo', () => {
        console.log('hello Grunt')
    })
}
```



当然不仅仅可以添加一个任务，还可以添加更多任务，第二个参数指定的是一个字符串的话，那这个字符串将会成为这个任务的描述，他会出现在 grunt 信息的帮助当中，通过 `yarn grunt --help` 去得到 grunt 的帮助信息 。当然，你同样可以通过 grunt 去运行 bar 这个任务，就是 `yarn grunt bar`。

```js
module.exports = grunt => {
    grunt.registerTask('foo', () => {
        console.log('hello Grunt')
    })
    
    grunt.registerTask('bar', '任务描述',() => {
        console.log('other task')
    })
}
```

此外，如果你在注册任务的时候你任务的名称叫 default 的话，那这个任务将会成为 grunt 的默认任务，那你在运行这个任务的时候就不需要去指定任务的名称，grunt 将自动调用 default。

```js
module.exports = grunt => {
    grunt.registerTask('foo', () => {
        console.log('hello Grunt')
    })
    grunt.registerTask('bar', '任务描述',() => {
        console.log('other task')
    })
    
    grunt.registerTask('default', () => {
        console.log('default task')
    })
}
```



一般我们会用 default 去映射一些其他的任务，那具体的做法就是在 registerTask 方法中，第二个参数传入一个数组，那这个数组当中可以去指定一些任务的名字，这个时候我们去执行 default 的时候，grunt 就会依次执行我们数组中的这些任务。回到命令行中，通过 grunt 执行默认任务（`yarn grunt`），那此时你会发现 grunt 先执行了 foo 任务，然后执行了bar，那 default 就相当于是把 foo 和 bar 串联到了一起。

```js
module.exports = grunt => {
    grunt.registerTask('foo', () => {
        console.log('hello Grunt')
    })
    grunt.registerTask('bar', '任务描述',() => {
        console.log('other task')
    })
    
    grunt.registerTask('default', ['foo', 'bar'])
}
```



最后我们尝试一下 grunt 中对异步任务的支持，我们在这个任务中通过 setTimeout 模拟一下异步操作，在异步任务完成过后，打印一个消息到控制台，通过命令 `yarn grunt async-task` 执行这个任务。通过执行我们发现 cosole.log() 并没有直接执行，这是 grunt 的一个特点，grunt 代码默认支持同步模式。

```js
module.exports = grunt => {
    grunt.registerTask('foo', () => {
        console.log('hello Grunt')
    })
    grunt.registerTask('bar', '任务描述',() => {
        console.log('other task')
    })
    grunt.registerTask('default', ['foo', 'bar'])
    
    // grunt.registerTask('async-task', () => {
    //     setTimeout(() => {
    //         console.log('async task')
    //     }, 1000)
    // })
    
    grunt.registerTask('async-task', function () {
        const done = this.async()
        setTimeout(() => {
            console.log('async task')
            done()
        }, 1000)
    })
    
}
```

如果你需要异步操作的话，你必须要使用 this.async 方法得到一个回调函数，在你的异步操作完成过后去调用这个回调函数标识一下这个任务已经被完成，如果我们要去函数中使用 this 的话，那我们函数就不能是箭头函数了，就要使用普通函数，在这个函数中我们使用 this.async 得到一个回调函数，那这一次我们在 setTimeout 完成过后除了打印消息以外，我们还需要去调用一下这个 done 回调函数，标识一下我们这个任务已经完成了，此时 grunt 就知道这是一个异步任务，他会等待 done 的执行，直到 done 被执行，grunt 才会结束这个任务的执行。

（目前还不知道 如果不用yarn的话该如何用执行grunt）

------

### Grunt 标记任务失败

如果你在构建任务的逻辑代码中发生错误，如我们需要的文件找不到了，此时我们就可以将这个任务标记为失败的任务，可以通过在函数体中去 return false 来实现。

例如在我们这个任务中 return false，运行这个任务 `yarn grunt bad`，终端中提示我们 bad 任务执行失败。那如果这个任务是在任务列表的话，那这个任务的失败会导致后续的任务不再被执行，前面的不影响，后续的都失败（例如用 default 连接 依次按顺序执行几个任务时，这里先不写进去）。

```js
module.exports = grunt => {
    grunt.registerTask('bad', () => {
        console.log('bad Grunt')
        return false
    })
}
```

而且命令行也会给提示，如果说你要去指定了一个 --force 参数的话，此时会采用一种强制方式去执行所有的任务，可以尝试一下，即 `yarn grunt default --force`，这样 bad任务即使运行失败了，后续的 bar 任务也是会正常去执行，这就是我们如何去标记任务失败以及标记任务失败过后的一些影响。

但是如果说你的任务是一个异步任务，那异步任务当中就没有办法直接通过 return false 去标记这个任务失败。此时我们需要给异步的回调函数指定一个 false 的实参就可以，标记为这个任务失败了。

```js
module.exports = grunt => {
    
    grunt.registerTask('bad-async', function () {
        const done = this.async()
        setTimeout(() => {
            console.log('bad async')
            done(false)
        }, 1000)
    })
    // 此时我们异步任务就会被标记为一个失败任务
}
```

运行一下：`yarn grunt bad-async` ，此时你会发现 bad-async 任务也是执行失败的，这就是我们在 grunt 任务中如何标记此任务为一个失败的任务，以及标记失败过后的影响。

------

### Grunt 的配置方法

除了 registerTask 方法之外，Grunt 还提供了一个用于去添加一些配置选项的 API，叫 initConfig，例如我们在使用 grunt 去为我们压缩文件时，我们就可以通过这种方式去配置我们需要压缩的文件路径。回到 gruntfile.js 文件。

这个方法接收一个对象形式的参数，对象的属性名也就是我们说的键，它一般与我们的任务名称保持一致，属性值可以是任意类型的数据，我们这给一个字符串，有了这个配置属性过后就可以在一个任务当中去使用这个配置属性。

```js
module.exports = grunt => {
    
    grunt.initConfig ({
        // foo: 'bar'
        foo: {
            bar: 123
        }
    })
    grunt.registerTask('foo', () => {
        // 注册一个叫做foo的任务，在foo任务中通过grunt提供的config方法去获取这个配置
        // config方法接收一个字符串参数，这个参数就是我们在config中所指定的属性的名字。试着运行打印看（yarn grunt foo）
        // console.log(grunt.config('foo')) // bar
        console.log(grunt.config('foo.bar')) // 123
    })
    
}
```

能打印出 bar 说明我们的配置是成功的，此外你的 initConfig 中属性值是一个对象的话，我们的 config 方法还支持一直高级的用法。此时我们在 config 中就可以通过 foo.bar 形式去拿到对应的属性值。不过其实一般使用的时候不需要去使用点的方式，因为我们可以直接通过config 把整个 foo 对象拿到，在这个对象上面通过点的方式去拿对应的 bar 属性也是可以的。

------

### Grunt 多目标任务

除了普通的任务形式以外，Grunt 中还支持一种叫多目标模式的任务，可以把它理解成子任务的概念，这种形式的任务在后续去具体通过 grunt 实现各种构建任务时非常有用。

通过 grunt 中的 `registerMultiTask()` 方法去定义，同样接收两个参数。1、任务名；2、函数，这个函数仍然使我们任务执行过程中所需要做的事情，然后运行任务（`yarn grunt build`），运行过程你会发现报错了，说没有为 build 任务去设置 targets，这是因为我们在<u>**设置这种多目标任务时需要为这种多目标的任务去配置不同的目标**</u>，配置的方式就是通过 grunt 的 initConfig 去配置。

```js
module.exports = grunt => {
	grunt.initConfig ({
        build: {
            css: '1', 
            js: '2'
            // 相当于为build任务添加了两个目标，分别叫css和js
        }
    })
    
    // 多目标任务
    grunt.registerMultiTask('build', function () {
        // console.log('build task') 
        console.log(`target: ${this.target}, data: ${this.data}`)  // target: xxx, data: xxx
    })
    
}
```

这个对象中要去指定一个与我们任务名称同名的属性 也就是 build，此时属性值就必须要是对象，对象中每一个属性的名字就是我们的目标名称。再次去运行时你会发现他会运行两个子任务，实际上在 grunt 中叫多目标，即我们 build 任务有2个目标，一个是css目标一个是js目标，那运行 build 任务时他会同时去执行这两个目标，相当于以两个子任务的形式去运行。如果要运行指定的目标，可以通过 `yarn grunt build:css`（冒号跟上目标名称），此时就只会运行对应的目标。在任务函数当中可以通过 this 去拿到当前执行的目标的名称，尝试重新执行（`yarn grunt build:css`），输出 target: css, data: 1。

需要注意的是，我们在 build 中指定的每一个属性的键都会成为一个目标，除了我们指定的 options 以外，在 options 指定的信息会作为这个任务的配置选项出现。此时再去执行 `yarn grunt build` 任务，你会发现并没有一个 target 叫 options，因为这个 options 他会作为任务的配置选项出现，那我们在任务的执行过程中就可以通过 this 的 options 拿到它的配置选项，options 是一个方法，可以去拿我们当前这个任务所有的配置选项的那个对象，再去执行 build，就会把任务的配置选项打印出来。

```js
module.exports = grunt => {
	grunt.initConfig ({
        build: {
            options: {
                foo: 'bar'
            },
            css: '1', 
            js: '2'
        }
    })
    
    grunt.registerMultiTask('build', function () {
        console.log(this.options()) // {foo: 'bar' } 这里是打印两次，因为有两个target
        console.log(`target: ${this.target}, data: ${this.data}`) 
    })
    
}
```



除了在任务中可以加这个配置选项之外，在目标当中，如果说目标的配置也是一个对象，在这个属性中也可以去添加一个 options ，在添加 options 时候他会覆盖掉对象当中的 options ，再次执行  `yarn grunt build`，此时 css 的 foo 是 baz，js 的foo还是 bar

```js
module.exports = grunt => {
	grunt.initConfig ({
        build: {
            options: {
                foo: 'bar'
            },
            css: {
                options: {
                    foo: 'baz'
                }
            }, 
            js: '2'
        }
    })
    
    grunt.registerMultiTask('build', function () {
        console.log(this.options()) // 此时 css 目标的 options 覆盖掉原来的 bar
        console.log(`target: ${this.target}, data: ${this.data}`) 
    })
    
}
```



------

### Grunt 插件

插件机制时 Grunt 的核心，很多构建任务都是通用的，例如你在你的项目中需要去压缩代码，别人也需要，所以说社区中就出现了很多预设的插件，这些插件内部都封装了一些通用的构建任务，一般情况下我们的构建过程都是由这些通用的构建任务组成的。如何具体使用插件中提供的构建任务。

1、npm 安装插件；2、到 gruntfile 中去载入这个插件提供的一些任务；3、根据这些插件的文档去完成相关的配置选项。

如：grunt-contrib-clean ，用来自动去清除在项目开发过程中产生的一些临时文件。绝大多数情况 grunt 插件的命名规范是 grunt-contrib-任务名，所以说我们这里的clean插件它提供的任务名称应该就叫做clean，尝试运行一下 `yarn grunt clean`，报错说 clean 任务没有配置对应的目标。由此可见 clean 实际上是之前的多目标任务，所以需要 initConfig 方式去配置不同的目标。

去为clean任务添加目标，目标名 temp ，值就是temp目标对应的配置选项可以设置为一个字符串，这个字符串当中就是我们这个 temp 目标所需要去清除的文件路径（这里用temp文件夹下的app.js），再次执行 `yarn grunt clean`，此时 temp 下的 app.js 就会被被删掉了。。。。也可以同通配符的方式去通配一些文件类型，例如删除一下所有的 txt 文件，再去执行clean任务，就全被删了。

```js
// 首先：yarn add grunt-contrib-clean
module.exports = grunt => {
    // 为任务添加配置选项
    grunt.initConfig ({
        clean: {
            temp: 'temp/app.js'
            // temp: 'temp/*.txt'  // temp下的所有txt文件
            // temp: 'temp/**'  //表示找到temp下所有的子目录以及子目录下的文件。temp下文件全被删，包括temp。 
        }
    })
    
	// 用这个方法加载插件中提供的一些任务
    grunt.loadNpmTasks('grunt-contrib-clean') 
    
}
```



------

### Grunt 常用插件及总结

#### grunt-sass

grunt 官方也提供了sass模块，但是那个模块需要你本机安装scss环境，使用起来很不方便，我们这里使用的 grunt sass 是一个 npm 模块，在内部通过npm形式去依赖 sass，这样就不需要对我们的机器有环境要求。grunt-sass 需要有一个 sass 模块的支持，这里使用的是 sass 官方提供的一个 npm  模块，然后安装到开发依赖中。

```
yarn add grunt-sass sass --dev
```

安装完之后回到 gruntfile 中载入，因为 grunt-sass 是多目标任务，这肯定是需要 initConfig 的方式去为 sass 任务去配置一些目标，配一个目标 main，main 需要指定我们 sass 的输入文件以及最终的输出的css文件路径。通过 files 属性去确定，它是一个对象，其中的键是输出的css文件路径，值就是输入的源 scss 路径。还不够，需要给 sass 添加 options，否则报没有传入implementation的错，它是来指定我们在 grunt-sass 中使用哪一个模块来处理 sass 编译。然后再运行这个任务：`yarn grunt sass`，此时就会在项目根目录下发现多了dist目录下的css目录，里面就有编译完成的 css 文件。

还可以有更多选项，比如添加一个 sourceMap 为 true，此时在编译过程中自动去生成对应的 sourceMap 文件。可以去 grunt-sass 的官方仓库里面的文档找到一些信息，这是一个简单介绍。

```js
const sass = require('sass')

module.exports = grunt => {
    // 为任务添加配置选项
    grunt.initConfig ({
        sass: {
        	options: {
                sourceMap: true,
                implementation: sass // 把引入的sass模块传入到这个属性中
    		},
            main: {
                files: {
                    'dist/css/main.css': 'src/scss/main.scss'
                }
            }
    	}

    })
    
	// 用这个方法加载grunt-sass提供的任务
    grunt.loadNpmTasks('grunt-sass') 
    
}
```



------

#### grunt-babel

此外我们还需要在编译过程中经常遇到的需求是编译ES6语法，ES6的语法编译器使用最多的是 babel，要在 grunt 中使用 babel 的也可以用 grunt-babel 插件，他也需要 babel 的核心模块。`yarn add grunt-babel @babel/core @babel/preset-env --dev`，有了这三个模块后就可以在我们的 gruntfile 中使用 babel 提供的任务了。

此时loadNpmTasks又多了一个，有办法减少使用，先安装 `yarn add load-grunt-tasks --dev` 模块后，导入这个模块，后面就不需要每次重复去导入不同的插件了。babel 作为ES6转换 实际上他不是es6的转换应该是ECMAScript的最新特性转换，支持转换部分特性，那preset就是你需要去转换哪些特性，他把一系列特性打包形成了叫 preset ，我们这使用的preset是env，他默认根据最新的ES特性做对应的转换，代码中ES6特性肯定会被转换。

全部搞定后执行babel任务：`yarn grunt babel`，此时dist目录就会出来js文件夹里有app.js。这里的babel也支持 sourceMap 选项，即我们也可以在 options 里去添加 sourceMap ，再去运行babel，此时js文件互对应生成sourceMap。

```js
const sass = require('sass')
const loadGruntTasks = require('load-grunt-tasks')

module.exports = grunt => {
    // 为任务添加配置选项
    grunt.initConfig ({
        sass: {
        	options: {
                sourceMap: true,
                implementation: sass // 把引入的sass模块传入到这个属性中
    		},
            main: {
                files: {
                    'dist/css/main.css': 'src/scss/main.scss'
                }
            }
    	},
        
        // 当然babel也需要配置选项，设置babel在转换的时候的preset
        babel: {
            options: {
                presets: ['@babel/preset-env'] //就会把我们最新的ECMAScript中特性全部加载进来
            },
            main: {
                files: {
                    'dist/js/app.js': 'src/js/app.js'
                }
            }
        }

    })
    
    loadGruntTasks(grunt) // 会自动加载所有的grunt插件中的任务
    
}
```



------

#### grunt-contrib-watch

当文件修改完过后需要自动去编译，此时在 grunt 中我们需要一个插件 grunt-contrib-watch（`yarn add grunt-contrib-watch --dev`），加载进来 但我们不需要loadnpmTasks啦，直接为 watch 添加配置选项就好了。

watch 需要去添加不同的目标，弄一个js目标去专门监视js文件的变化，配置完后在watch里面就有一个对JS的watch，以此类推也可以弄一个样式文件的watch，配置完可以运行watch任务：`yarn grunt watch`，启动watch 任务后就开始监视，有变动就开始自动执行任务。

```js
const sass = require('sass')
const loadGruntTasks = require('load-grunt-tasks')

module.exports = grunt => {
    // 为任务添加配置选项
    grunt.initConfig ({
        sass: {
        	options: {
                sourceMap: true,
                implementation: sass // 把引入的sass模块传入到这个属性中
    		},
            main: {
                files: {
                    'dist/css/main.css': 'src/scss/main.scss'
                }
            }
    	},
        
        // 当然babel也需要配置选项，设置babel在转换的时候的preset
        babel: {
            options: {
                presets: ['@babel/preset-env'] //就会把我们最新的ECMAScript中特性全部加载进来
            },
            main: {
                files: {
                    'dist/js/app.js': 'src/js/app.js'
                }
            }
        },
        watch: {
            js: {
                // files指定我们需要监视的文件，直接设置为一个数组就好了，因为不需要输出文件，只需要监视源文件
                // 不过一般我们会用通配符去通配js下面所有的JS文件。
                files: ['src/js/*.js'],
                tasks: ['babel']
                // 还需要添加一个选项 tasks，当你这些文件发生改变，你需要执行什么任务，我们这里要执行 babel
            },
            css: {
                files: ['src/scss/*.scss'],
                task: ['sass'] //scss一变 就自动执行sass任务
            }
        }

    })
    
    loadGruntTasks(grunt) // 会自动加载所有的grunt插件中的任务
    
    grunt.registerTasks('default', ['sass', 'babel', 'watch'])
    
}
```

一般我们会给watch做一个映射，在这个default中先去执行 sass 和 babel，最后执行babel，确保我们在启动的时候就会执行一次编译操作然后再启动监听，这样应该更合理些，default可以不需要指定任务名称，然后运行default（`yarn grunt`）。所以就实现了先编译后监听。

<u>**不过多介绍，因为 grunt 已经推出历史舞台了，介绍 grunt 最主要的原因是它算是最早的。**</u>



------

## Gulp — 最流行的前端构建系统

安装gulp的同时他会同时安装gulp-cli的模块。即在.bin下面会出gulp的命令。后续就可以通过这个命令去运行我们的一些构建任务。核心特点：高效易用，因为使用gulp的过程非常简单。大体的过程是先在项目中安装一个叫 Gulp 的开发依赖，然后在项目的根目录去添加 gulpfile.js 文件，用于编写我们需要 gulp 自动执行的一些构建任务，完成后就可以在命令行终端中使用 gulp 这个模块提供的 cli 去运行这些构建任务。

```bash
yarn init --yes
yarn add gulp --dev 
code gulpfile.js # 创建JS文件
```

定义一些需要gulp执行的一些构建任务，即这个文件会是 gulp 的入口文件，因为这个文件是运行在 node.js 环境中，所以可以在这个文件中使用 common.js 规范。这个文件去定义构建任务的方式是<u>**通过导出函数成员的方式去定义**</u>。具体就是通过 exports 导出一个叫做 foo 的成员，这个成员的值是一个函数，在这个函数体中可以xxxx，相当于定义了一个foo的任务。

```js
// 此时gulpfile中相当于定义了一个foo的任务
exports.foo = done => {
    console.log('foo task')
    done() // 标识任务完成 
}
```

可以通过 gulp 提供的 cli 去运行这个任务（`yarn gulp foo`），指定执行foo任务会报错。在最新的 gulp 中取消了同步代码模式，约定了<u>**gulp每个任务都必须是异步的任务**</u>，当任务执行完之后需要通过调用回调函数或其他的方式去标记这个任务已经完成。可以通过 foo 的形参得到，这个 done 就是一个函数，调用它再去执行命令就是任务正常启动和结束。这就是在gulp定义一个任务的操作方式。

如果你的任务名叫default，他会作为gulp的默认任务出现，运行时就不用指定任务名了（`yarn gulp`）。

```js
exports.foo = done => {
    console.log('foo task')
    done()
}
exports.default = done => {
    console.log('default task')
    done()
}
// const gulp = require('gulp')
// gulp.task('bar', done => {
//     console.log('bar working~')
//     done()
// })
```

(在 gulp 4.0 以前，去注册 gulp 任务是需要 gulp 模块里的一个方法去实现。1、通过 require 方式载入 gulp 模块；2、借助于这个模块提供的task方法去注册任务，也需要去接收一个任务函数，同样通过形参接收任务完成过后的回调函数，然后尝试运行bar任务也可以正常工作，说明 4.0后保留了这个API，但不被推荐，推荐第一种导出函数成员的方式去定义我们的 gulp 任务。)

------

### Gulp 的组合任务

这有3个函数，可以把这种未被导出的成员函数理解成私有的任务，各自模拟了一个需要执行1s的任务，这里并不能通过 gulp 直接去运行他们，我们可以通过gulp模块提供的 series 和 parallel 这两个API把他们组合成一个组合任务。

通过require载入这两个API，然后创建一个foo任务，这个任务通过 series去创建，series是一个函数，可以接收任意个数的参数，每个参数都可以是一个任务，series会自动去按照顺序依次执行这些任务，然后尝试使用他们（`yarn gulp foo`）会依次执行task1、2、3。

```js
const { series, parallel } = require('gulp')
const task1 = done => {
    setTimeout(() => {
        console.log('task1 working~')
        done()
    }, 1000)
}

const task2 = done => {
    setTimeout(() => {
        console.log('task2 working~')
        done()
    }, 1000)
}

const task3 = done => {
    setTimeout(() => {
        console.log('task3 working~')
        done()
    }, 1000)
}
exports.foo = series(task1, task2, task3) // 串行
exports.bar = parallel(task1, task2, task3) // 并行
```

除了创建这种串行的任务结构，还可以创建一种并行的任务结构，这种方式需要通过 gulp 里面提供的 parallel API去实现，然后再去运行bar任务（`yarn gulp bar`），你会发现这3个任务会被同时启动，这种方式就是同步去执行这3个任务。

总的来说，创建**<u>并行/串行任务</u>**在我们实际创建构建工作流很有用，例如我们编译css和编译js的任务，他们是互不干扰的，那这两个任务就可以通过并行的方式去执行，这样会提高一些构建效率。再比如去部署，那部署的任务需要先执行编译任务，那这个时候就需要 series 这种串行的模式去执行这两个任务。

------



### Gulp 的异步任务

gulp 当中的任务都是异步任务，也就是我们在JS当中经常提到的异步函数，去调用一个异步函数时是没有办法直接去明确这个调用是否完成的，都是在函数内部通过回调或者事件的方式去通知外部这个函数执行完成，那在异步任务当中同样面临这个如何去通知 gulp 我们的完成情况的问题，针对这个问题 gulp 中有很多解决方法。

1、通过回调的方式解决

```js
// gulpfule.js
exports.callback = done => {
    console.log('callback task')
    done()
}
exports.callback_error = done => {
    console.log('callback task')
    done(new Error('task failed'))
}
```

当我们想执行过程中去报出一个错误，去阻止剩下任务执行的时候，可以通过给回调函数的第一个参数去指定一个错误对象就可以了，然后执行这个任务`yarn gulp callback_error`，此时就会报错，而且如果你是多个任务同时执行的话，那后续的任务也就不会再去工作了。



那有了回调函数我们自然会联想ES6中提供的promise的方案，它相对于回调函数是比较好的替代方案，它避免了代码回调嵌套过深问题。在gulp中同样支持promise的方式。具体要在任务的执行函数中去return一个promise对象，这个地方通过return promise resolve返回一个成功的promise，一旦当我们返回的promise对象resolve了，意味着任务结束了。需要注意的是resolve不需要去返回任何的值，因为 gulp 中会忽略掉这个值。

自然也会涉及到promise的失败reject，一旦你return是一个失败的promise，那我们的 gulp 会认为是一个失败的任务，它同样会结束后续所有的任务执行。

```js
exports.promise = () => {
    console.log('promise task')
    return Promise.resolve()
}
// 然后 yarn gulp promise

exports.promise_error = () => {
    console.log('promise task')
    return Promise.reject(new Error('task failed~'))
}
// 然后 yarn gulp promise_error
```



然后我们又会想到ES7中的async/await，实际上它是promise的语法糖，可以然我们使用promise的代码更容易理解，如果你的node环境是8以上的版本的话，那你可以使用这种方式。就是将我们的任务函数定义为一个异步的函数，在这个函数中去 await 一个异步任务，其实我们 await 的就是一个promise对象，那这样通过定义一个单独的promise函数去做一个尝试。这个promise函数只是把 setTimeout 包装成一个promise的方式，有了这个函数就可以在 async 去 await 这个函数，我们在执行这个async 函数的时候它就会这个位置等待这个promise的resolve，然后一旦resolve完成过后才回去执行后续的代码，这个实际上是一种语法糖，实际内部还是promise。这种方式只受限制于你的node环境，只要你的node环境支持 async/await 就可以使用这种方式。

```js
const timeout = time => {
    return new Promise(resolve => {
        setTimeout(resolve, time)
    })
}
exports.async = async () => {
    await timeout(1000)
    console.log('async task')
}
// yarn gulp async
```

以上就几种都是JavaScript中处理异步的常见方式，这些方式在gulp中都被支持，除了这些方式以外，gulp中还支持另外几种方式，其中通过 stream 的方式是最为常见的，因为我们的构建系统大都是在处理文件，所以这种方式也是最常用到的一种。

具体来看就是在任务函数中需要去返回一个 stream 对象，例如我们通过fs模块中提供的createReadstream方法去创建一个读取文件的文件流，这样的话就尝试着读取下package.json，此时这个readStream就是一个文件流对象，我们还需要去创建一个写入文件的文件流，这个我们写入到一个叫temp.txt的文件，我们可以把readStream通过`pipe`方式导到writeStream中，这样就可以把它理解成从一个水池子往另外一个水池子里面倒水，就会起到一个文件复制的作用，最后把readStream给return出去，再到命令行中运行一下这个任务 `yarn gulp stream`。

```js
const fs = require('fs')
exports.stream = () => {
    // 创建文件读取流，参数是要读取的文件路径
    const readStream = fs.createReadStream('package.json') // 读取 
    // 创建文件写入流
    const writeStream = fs.createwriteStream('temp.text') // 写入
    // 把读取出来的文件流导入写入流（可以理解是 左到右的导入？）
    readStream.pipe(writeStream)
    // 通过return的方式把这个stream（流）给return出去，这样gulp就可以根据这个流的状态去判定这个任务是否执行完成
    return readStream
}
```



模拟结束：任务结束的时候是readStream end的时候，因为stream 中都有一个事件就是 end 事件，一旦当这个读取的文件流读取完成过后，就会触发 end 事件，从而 gulp 就知道你这个任务完成了，也可以通过以下这个代码去模拟一下 gulp 当中做的事情，gulp 中接收到stream过后只是为他注册了一个end事件，在这个end事件中结束了我们这个任务的执行，我们通过end事件去调用done函数去模拟 gulp 结束任务的操作，此时任务正常结束，所以gulp只是注册了个end事件而已。

```js
const fs = require('fs')
exports.stream = done => {
    const readStream = fs.createReadStream('package.json')
    const writeStream = fs.createwriteStream('temp.text')
    readStream.pipe(writeStream)
    readStream.on('end', () => {
        done()
    })
}
```



------



### Gulp 构建过程核心工作原理

构建过程大多数情况都是将文件读出来然后进行一些转换，最后去写入到另外一个位置，可以想象一下，在没有构建系统的情况下，我们也是人工按照这个过程去做的。通过最原始的底层node的文件流API去模拟实现这个过程。

需要导入 stream 模块中的 transform 类型，有了这个类型过后就可以通过这个类型去创建一个文件转换流对象。通过 transform 去 new 一个transform，这个 transform需要去指定一个transform属性，这个属性就是我们转换流的核心转换过程，**<u>可以通过这个函数当中的 chunk 拿到我们文件读取流当中读取到的文件内容</u>**，通过toString的方式把它转换成字符串，因为它读出来是一个字节数组。定义一个 input 让他等于 chunk 的 toString ，完成过后就可以通过input拿到这个文件的文本内容。

再通过replace方法先去把空白字符全部替换掉，再去替换掉这个代码当中的css注释，我们将这个转换完的结果放到一个 output 变量中，最后我们在 callback 时候将这个 output 返回出去，这样我们就完成了一个转换过程。注意这个 callback 函数是一个错误优先的回调函数，第一个参数一个传入错误对象，如果没有发生错误的话可以传入 null，那这个 output 就会作为我们转换完的结果 接着往后去导出。此时我们再将这个 read 的 pipe 操作中间去添加一步 pipe，就是 read 先去 pipe 到这个 transform 转换流当中完成这个转换，将转换完的结果再 pipe 到写入流当中，从而起到文件转换构建过程。

```js
const fs = require('fs')
const { Transform } = requrie('stream') // 看样子是stream模块中的一个类型

exports.default = () => {
    const read = fs.createReadStream('normalize.css')
    const write = fs.createwriteStream('normalize.min.css')
    const transfrom = new Transform({
        transform: (chunk, endcoding, callback) => {
            // 核心转换过程实现
            // chunk => 读取流中读到的内容（Buffer）
            const input = chunk.toString()
            const output = input.replace(/\s+/g, '').replace(/\/\*.+?\*\//g, '') // 空格和注释全部替换掉
            callback(null, output)
        }
    })
    // 把读取出来的文件流导入 写入文件流
    read
        .pipe(transfrom) // 转换
    	.pipe(write) // 写入
    
    // return这个过程是将让gulp可以根据这个流的状态去判定这个任务是否执行完成
    return read
}
```

这里有3个核心概念，读取流、转换流、写入流。基于流的构建系统，至于在 gulp 中构建过程为什么使用文件流的方式，这是因为gulp希望实现一个构建管道的概念，这样在后续去做一些扩展插件的时候就可以有一个统一的方式，这些会在后续去接触到插件的使用过后就有明确体会。

------



### Gulp 文件操作 API

相比于底层node的API，Gulp 的API更强大也更容易使用，至于负责文件加工的转换流，绝大多数情况我们都是**<u>通过独立的插件来提供</u>**。这样的话，我们在实际去通过 gulp 创建构建任务时的流程就是先通过 src 方法去创建一个读取流，然后再借助于插件提供的转换流来实现文件加工，最后再通过 gulp 提供的 dest 方法去创建一个写入流，从而写入到目标文件。

在默认任务中通过src方法去创建一个文件的读取流(文件路径)，通过pipe方式导出到dest所创建的写入流中，dest 方法只需要去指定一个写入目标目录就可以，这里是dist目录，最后需要return方式将这个创建的读取流return出去。这样gulp就可以控制我们任务完成，回到命令行去尝试运行。然后运行 `yarn gulp`。

```js
// 通过require的方式去载入gulp模块提供的src方法和dist方法
const { src, dest } = require('gulp')

exports.default = () => {
    return src('src/normalize.css') // 可以是*.css 意味着src目录下所有css文件也会被复制到dist目录
    	.pipe(dest('dist'))
}
```



那相比于原始的API，gulp模块所提供的API要更为强大些，因为我们可以在这使用通配符的方式去匹配批量文件。当然构建的过程最重要的是文件的转换，这里如果需要去完成文件的压缩转换，可以去安装一个叫做 gulp-clean-css 这样的插件，这个插件提供了压缩css代码的转换流 （`yarn add gulp-clean-css --dev`）。有了这个插件之后就可以在dest之前，先去pipe到我们cleanCss所提供的转换流中，这样他就会先经过转换，最后再被写入到写入流中，执行命令就是压缩过的css了。

```js
const { src, dest } = require('gulp')
const cleanCss = require('gulp-clean-css')

exports.default = () => {
    return src('src/*.css')
    	.pipe(cleanCss())
    	.pipe(dest('dist'))
}
```

如果还需要在这个过程执行多个转换的话可以继续在中间去添加额外的pipe操作，例如添加 gulp-rename 插件，在 cleanCss过后接着去 pipe 到 rename 的转换流当中，rename 可以指定一个 extname 的参数，用于指定我们重命名的扩展名为 .min.css。

```js
const { src, dest } = require('gulp')
const cleanCss = require('gulp-clean-css')
const rename = require('gulp-rename')

exports.default = () => {
    return src('src/*.css')
    	.pipe(cleanCss())
    	.pipe(rename({ extname: 'min.css' }))
    	.pipe(dest('dist'))
}
```



------

### Gulp 案例 - 样式编译

看看如何使用 gulp 去完成一个网页应用的自动化构建工作流。所有的构建需求都需要在 gulpfile.js 中完成。

```bash
yarn add gulp --dev 
# 安装完之后就可以在根目录下新建一个 gulpfile.js 作为我们gulp的入口，需要在里面定义一些构建任务
```

定义style任务，先定义成私有的任务即私有函数，后续再通过 module.export 去选择性导出哪些函数。过程中肯定需要用到 gulp 所提供的API，先把他们导入。这里的style是私有任务，并不能通过gulp去执行。要测试的话要把它导出出去。然后再 `yarn gulp style` 执行style任务。

```js
const { src, dest } = require('gulp')
const style = () => {
    return src('src/assets/styles/*.scss')
    	.pipe(dest('dist'))
}
// 导出一个对象，对象中所有的成员都可以在外界被使用，跟我们用export导出实际上是一样的。
module.exports = {
    style
}
```



但是这不是我们想要的，因为我们想输出的也是原来的src目录结构输出，此时只是弄完之后直接丢进 dist 而已。这个问题可以通过 src 去指定一个选项参数叫 base，就是我们在转换的基准路径是什么，那基准路径是 src，此时就会把 src 后面一系列目录结构都保留下来，保存一下再执行`yarn gulp style`。

```js
const { src, dest } = require('gulp')
const style = () => {
    return src('src/assets/styles/*.scss', { base: 'src' })
    	.pipe(dest('dist'))
}

module.exports = {
    style
}
```

但还差一点，没有加上文件的转换（只是文件复制过去了个scss文件），按照之前转换需要插件提供的一些转换流来实现，所以要再安装一个插件（`yarn add gulp-sass --dev`）。安装这个的时候它内部会安装node-sass，而 node-sass 是一个C++的模块，会对C++程序集的依赖，这些二进制的包需要去通过国外站点下载有时候会下载不了，可以通过淘宝的镜像源单独为node-sass配置一个镜像，所以我不知道提这个事情对我们有什么影响  =。 =。

这里安装完成过后就可以使用插件了，引入后可以在 src 和 dest 之间需要去 pipe 到我们的 sass，**<u>基本上每一个插件提供的都是一个函数，这个函数的调用结果会返回一个文件的转换流</u>**，这样的话我们就可以去实现文件的转换过程，再去运行（`yarn gulp style`）。

```js
const { src, dest } = require('gulp')
const sass = require('gulp-sass') // 引入
const style = () => {
    return src('src/assets/styles/*.scss', { base: 'src' })
    	.pipe(sass({ outputStyle: 'expanded' }))
    	.pipe(dest('dist'))
}

module.exports = {
    style
}
```

有个问题，原来那里有3个 scss 文件，最后在输出只有1个css文件，原因是我们在 sass 模块工作的时候<u>他会认为这种下划线开头的样式文件都是我们主文件中依赖的一些文件，他就不会被转换</u>，会被忽略掉，所以最终只有没有下划线开头的 scss 文件会被转换过去。

有个细节就是它输出的 css 文件里 结束的 } 会在最后一个属性后面，我们一般是放在空行里。可以通过给 sass 指定一个选项去完成，就是上面改成 `pipe(sass({ outputStyle: 'expanded' }))`的完全展开形式，再执行后就会按照完全展开的形式生成样式代码。（但是我觉得没必要，因为最后打包我是想把空格的去掉）。

------



### Gulp 案例 - 脚本编译

中间还是要一个转换流插件，需要单独安装（`yarn add gulp-babel --dev`），载入后在 dest 之前 pipe 到 babel 插件中，然后临时导出出去，为什么说临时呢，因为这些任务后面会通过 series 和 parallel 这两个方法去变成一些组合的任务，不会单独去执行，所以现在先把他们定义成私有的任务，临时导出只是为了测试而已。

oh no，因为这里用的是babel去转换，而babel这个插件它只是帮你去唤醒 babel/core 里面的转换过程，他没有像刚刚这个 gulp-sass 自动去帮你安装 node-sass 核心转换模块，这里的转换模块需要你手动去装才行（yarn add @babel/core @babel/preset-env --dev），env这个模块默认会把你全部的ES6或者所有新特性都会给你转换，此时就可以回到 babel 配置中去添加 preset 的配置。再去执行 script 任务就OK啦。

```js
const { src, dest } = require('gulp')
const sass = require('gulp-sass') 
const babel = require('gulp-babel') 

const style = () => {
    return src('src/assets/styles/*.scss', { base: 'src' })
    	.pipe(sass())
    	.pipe(dest('dist'))
}

// babel记得传对象。babel默认只是ECMAScript的转换平台，提供一个环境给你，具体去做转换的实际上是babel里面它内部的插件。而preset就是一些插件的集合。
const script = () => {
    return src('src/assets/scripts/*.js', { base: 'src' })
    	.pipe(babel({ presets: ['@babel/preset-env'] }))
    	.pipe(dest('dist'))
}

module.exports = {
    style,
    script
}
```



------



### Gulp 案例 - 页面模板编译

`'src/**/*.html'`，代表src下面任意子目录下的html文件

```js
// yarn add gulp-swig --dev
const { src, dest } = require('gulp')
const sass = require('gulp-sass') 
const babel = require('gulp-babel')
const swig = require('gulp-swig')

const data = {
    menus: [],
    pkg: require('./package.json'),
    date: new.Date()
}

const style = () => {
    return src('src/assets/styles/*.scss', { base: 'src' })
    	.pipe(sass())
    	.pipe(dest('dist'))
}
const script = () => {
    return src('src/assets/scripts/*.js', { base: 'src' })
    	.pipe(babel({ presets: ['@babel/preset-env'] }))
    	.pipe(dest('dist'))
}

const page = () => {
    return src('src/*.html', { base: 'src' })
    	.pipe(swig({ data })) // 本来是 data: data  用ES6语法简写
    	.pipe(dest('dist'))
}

module.exports = {
    style,
    script,
    page
}
```



创建一个组合任务把他们3者组合到一块，因为这三个任务他们可以 一旦要去运行的话不可能单独去运行某一个，一般都是同时运行。所以单独创建一个 compile 的编译任务组合任务。三个任务没有任何的牵连，所以说我们可以让这3个任务同时开始执行，这样可以提高我们构建的效率，那就应该使用 parallel。

```js
const { src, dest, parallel } = require('gulp')
const sass = require('gulp-sass') 
const babel = require('gulp-babel')
const swig = require('gulp-swig')

const data = {
    menus: [],
    pkg: require('./package.json'),
    date: new.Date()
}

const style = () => {
    return src('src/assets/styles/*.scss', { base: 'src' })
    	.pipe(sass())
    	.pipe(dest('dist'))
}
const script = () => {
    return src('src/assets/scripts/*.js', { base: 'src' })
    	.pipe(babel({ presets: ['@babel/preset-env'] }))
    	.pipe(dest('dist'))
}

const page = () => {
    return src('src/*.html', { base: 'src' })
    	.pipe(swig({ data })) // 本来是 data: data  用ES6语法简写
    	.pipe(dest('dist'))
}

const compile = parallel(style, script, page) 
// 此时只需要导出一个compile任务 yarn gulp compile
module.exports = {
    compile
}
```

------



### Gulp 案例 - 图片和字体文件转换

图片转换：需要把图片全部读取出来然后借助插件（`yarn add gulp-imagemin --dev`）完成压缩，这个插件内部依赖的模块也是一些通过一些C++完成的模块，所以涉及到需要下载二进制的程序集，这些程序集大部分是在github下载，国内去下载github资源会相对容易出问题。字体文件：把它拷贝一下就行了。运行一下发现只压缩了1张图片，原因是其他格式是不支持压缩的。

全部放到 compile 中

```js
const { src, dest, parallel } = require('gulp')
const sass = require('gulp-sass') 
const babel = require('gulp-babel')
const swig = require('gulp-swig')
const imagemin = require('gulp-imagemin')

const data = {
    menus: [],
    pkg: require('./package.json'),
    date: new.Date()
}

const style = () => {
    return src('src/assets/styles/*.scss', { base: 'src' })
    	.pipe(sass())
    	.pipe(dest('dist'))
}
const script = () => {
    return src('src/assets/scripts/*.js', { base: 'src' })
    	.pipe(babel({ presets: ['@babel/preset-env'] }))
    	.pipe(dest('dist'))
}

const page = () => {
    return src('src/*.html', { base: 'src' })
    	.pipe(swig({ data })) // 本来是 data: data  用ES6语法简写
    	.pipe(dest('dist'))
}
const font = () => {
    return src('src/assets/images/**', { base: 'src' }) // 两个星号通配下面所有文件
    	.pipe(imagemin())
    	.pipe(dest('dist'))
}
const font = () => {
    return src('src/assets/fonts/**', { base: 'src' })
    	.pipe(imagemin())
    	.pipe(dest('dist'))
}

const compile = parallel(style, script, page, image, font) 
// 此时只需要导出一个compile任务 yarn gulp compile
module.exports = {
    compile
}
```

------



### Gulp 案例 - 其他文件及清除

把public文件目录中的文件再去做一个拷贝，这个是额外拷贝的任务，个人觉得 compile 定义是编译 src 下面的文件，也放进去的话容易混淆，所以单独添加一个新的任务叫 build，它通过 parallel 去执行compile，就是组合的基础上又组合一次。

```js
// 这里先不写上面的那些。就是额外的一些文件 拷贝过去就可以了
const extra = () => {
    return src('public/**', { base: 'public' })
    	.pipe(dest('dist'))
}

const compile = parallel(style, script, page, image, font) 
const build = parallel(compile, extra)
module.exports = {
    compile, // 如果你想在外面单独使用compile，也可以把它单独导出去，也可以不用。
    build
}
```

此外再做一些开发体验的增强，如集成一个web服务器进来，让我们可以有一个开发测试的服务器。

做这个之前先做一个自动清除dist目录下的文件（`yarn add del --dev`），这个模块不是 gulp 的插件，只不过是在 gulp 中可以使用，因为之前使用 gulp 定义任务时，gulp 的任务并不一定说必须要通过 src 去找文件流最终 pipe 到 dist 中，不一定是这样的。这个 del 可以帮我们删除指定的文件，而且他是一个promise方法，那 gulp 任务支持 promise 模式的，所以可以定义一个 clean 任务。

这个 del 方法返回的是promise，意味着我们在 delete 完成过后可以去标记这个 clean 任务执行完成，放在build之前。给这个build任务再去包装一下，要引进series了因为这个任务就不能跟其他任务同时执行了。因为他需要先删除dist目录下的文件然后再生成，不然就会出现生成的文件被删除。

```js
const { src, dest, parallel, series } = require('gulp')
// 不是gulp的模块 可以在放前面导
const del = require('del')
const clean = () => {
    // 指定一个数组，这个数组可以放任意文件路径
    return del(['dist'])
}

const compile = parallel(style, script, page, image, font) 
const build = series(clean, parallel(compile, extra)) // 这样的话build先去clean
module.exports = {
    compile,
    build
}
```

------



### Gulp 案例 - 自动加载插件

随着构建任务越来越复杂，使用到的插件也越来越多，如果都用手动的方式去载入插件的话require操作会很多，可以通过一个插件解决这个问题（`yarn add gulp-load-plugins --dev`）。

pulgins是一个对象，你所有的插件都会成为这个对象下面的属性，那命名的方式就是把 gulp- 给它删除掉，如果说你的插件名字是 gulp- 后面是还有-（xxx-xxx），那就会用驼峰命名大写字母。然后把所有的都重命名过去 全部改成 plugin.xxx 。

如下：执行 `yarn gulp build`

```js
const { src, dest, parallel, series } = require('gulp')
const del = require('del')
// 自动加载所有plugins
const loadPlugins = require('gulp-load-plugins') //导出的是方法
const plugins = loadPlugins()

const data = {
    menus: [],
    pkg: require('./package.json'),
    date: new.Date()
}

const clean = () => {
    return del(['dist'])
}

const style = () => {
    return src('src/assets/styles/*.scss', { base: 'src' })
    	.pipe(plugins.sass({ outputStyle: 'expanded' }))
    	.pipe(dest('dist'))
}
const script = () => {
    return src('src/assets/scripts/*.js', { base: 'src' })
    	.pipe(plugins.babel({ presets: ['@babel/preset-env'] }))
    	.pipe(dest('dist'))
}

const page = () => {
    return src('src/*.html', { base: 'src' })
    	.pipe(plugins.swig({ data })) // 本来是 data: data  用ES6语法简写
    	.pipe(dest('dist'))
}
const font = () => {
    return src('src/assets/images/**', { base: 'src' }) // 两个星号通配下面所有文件
    	.pipe(plugins.imagemin())
    	.pipe(dest('dist'))
}
const font = () => {
    return src('src/assets/fonts/**', { base: 'src' })
    	.pipe(imagemin())
    	.pipe(dest('dist'))
}

const compile = parallel(style, script, page, image, font) 
const build = series(clean, parallel(compile, extra))
module.exports = {
    compile,
    build
}
```

------



### Gulp 案例 - 开发服务器

除了对文件的构建操作以外，还需要一个开发服务器，用于去开**<u>发阶段调试我们的应用</u>**，可以通过 gulp 启动并且管理这个开发服务器，这样的话就可以在后续去配合我们其他的一些构建任务，去实现在代码修改过后自动去编译并且自动去刷新浏览器页面，这样就会大大提高我们在开发阶段的效率，因为他会减少我们在开发阶段的重复操作。

（`yarn add browser-sync --dev`）这个模块会提供给我们一个开发服务器，相对于我们普通使用 express 创建的web服务器来说，这个有更强大的功能，它支持我们在代码修改过后自动热更新到浏览器中，可以及时看到最新的页面效果，在 gulp 中使用这个模块，他并不是gulp的插件，只是我们通过gulp去管理它而已，所以需要单独引入这个模块。

这个模块提供了一个 create 方法用于去创建一个服务器，我们这儿定义一个 bs 变量，它会自动创建一个开发服务器，将这个开发服务器单独定义到一个任务中去启动，定义一个serve任务，最核心的配置是server，server需要指定网站的根目录，也就是web服务器它需要把哪个目录作为网站根目录（肯定是dist目录啦），启动serve任务（yarn gulp serve），他会自动唤起浏览器。

这里要单独bs单独加一个特殊的路由，让他对于这种**<u>node_modules这种请求</u>**，我们都给它指到同一个目录下面去，通过routes去指定，它优先于 baseDir 的配置，就是一旦我们请求发生后会先去看在 routes 里面有没有对应的配置，如果有的话会先走 routes 里面的配置，否则的话就会找 baseDir 下面对应的文件。

bs.init 还可以指定一些其他的选项，比如 notify，作用是页面启动可以不弹出提示（会提示browser-sync是否连接上，可能会影响页面调试样式，可以false给它关掉）。port 端口默认是 3000，可以改。还有open，因为我们 browser-sync 启动会自动去帮你打开浏览器，那这个操作如果你觉得不好的话，可以设置为false，根据情况决定。

```js
// 这里省略很多
const browserSync = require('browser-sync')
const bs = browserSync.create()
const serve = () => {
    // 初始化这个web服务器的一些相关配置
    bs.init({
        notify: false,
        port: 2080,
        // open: false,
        files: 'dist/**' // dist下面所有文件
        server: {
            baseDir: 'dist',
            routes: {
                '/node_modules': 'node_modules' // 键就是我们请求的前缀
                // 这里是相对路径，相对于我们网站的根目录下面的node_modules
            }
        }
    })
}
module.exports = {
    compile,
    build,
    serve
}
```

一步一步来。我们首先**考虑在dist下面的文件发生变化后，怎么让浏览器及时更新过来**。再指定一个参数 files，可以指定一个字符串，就是用来去被 browser-sync 启动过后监听的一个路径通配符，你想要哪些文件发生改变过后这个 browser-sync 自动更新浏览器，在这里就可以通过通配符的方式指定。

------



### Gulp 案例 - 监视变化以及构建优化

重点考虑一下如何在 src 下面的源代码修改过后自动去编译，这个过程我们需要借助于 gulp 提供的另外一个 API叫 watch。watch API 会自动监视一个文件路径的通配符，然后根据这些文件的变化决定是否要重新去执行某一个任务，我们这**<u>要监视的是所有产生构建任务的路径</u>**。如 sass 文件修改过后我们要执行的是 style 任务，那这几个文件修改过后就会执行相应的任务，这些任务一旦触发过后就会把对应 dist 下面的文件被覆盖掉，那被覆盖掉的话 browserSync 就会监视到 dist 里的文件变化，那会自动去同步到浏览器，这样就实现我们一开始设想的<u>源代码修改过后自动编译到 dist 中再同步到浏览器</u>。

在启动WEB服务器时候，把 baseDir 指定两个目录分别是 dist 目录和 src 目录，其中 src 目录对于像图片/字体/public 这些我们把他们就直接放在原位置不然他们参与这次的构建，它只是在最终发布上线之前去做一下构建就可以了。**<u>baseDir 指定为数组后，他会先到数组中第一个目录去找，如果找不到这个文件就会依次往后去找</u>**。src 只是做了无损压缩，我们这是让他请求源文件，这样我们在开发阶段就减少了一次构建过程，public也一样，只是拷贝过去而已，咱们不需要在开发阶段构建他们，减少构建次数提高效率。

```js
const { src, dest, parallel, series, watch } = require('gulp')
const browserSync = require('browser-sync')
const bs = browserSync.create()
const serve = () => {
    watch('src/assets/styles/*.scss', style)
    watch('src/assets/scripts/*.js', script)
    watch('src/*.html', page)
    // watch('src/assets/images/**', image)
    // watch('src/assets/fonts/**', font)
    // watch('public/**', extra)
    // 当然还有个需求是希望src下面的图片字体以及public下文件变化过后也能更新一下浏览器。通过1个watch
    // 这3种文件变化过后只需要去调用一下bs模块提供的reload方法就可以了。可以理解为一个任务，因为在gulp中任务就是一个函数
    watch([
        'src/assets/images/**',
        'src/assets/fonts/**',
        'public/**'
    ], bs.reload)
    
    bs.init({
        notify: false,
        port: 2080,
        files: 'dist/**'
        server: {
            baseDir: ['dist', 'src', 'public'],
            routes: {
                '/node_modules': 'node_modules' 
            }
        }
    })
}
// 这里可能很因为swig模板引擎缓存机制导致页面不变化，需要在swig选项把cache设置为false，见源码72行
const compile = parallel(style, script, page) // 算是总的子任务，开发阶段运行compile就可以了
const build = series(clean, parallel(compile, image, font, extra)) // 上线前执行的任务

// dev阶段启动编译样式脚本页面，然后启动serve
const develop = series(compile, serve)

module.exports = {
    clean,
    compile,
    build,
    develop
}
```

你每次文件发生变化过后在watch都能监视到，在任务后面再 pipe 一下 bs.reload，执行完的结果就是一个 只是把内部文件 流里面的信息推到浏览器，以流的方式往浏览器推，这种方式会更常见。

```js
const style = () => {
    return src('src/assets/styles/*.scss', { base: 'src' })
    	.pipe(plugins.sass({ outputStyle: 'expanded' }))
    	.pipe(dest('dist'))
    	.pipe(bs.reload({ stream: true }))
}
```



总结：使用了 browserSync 提供的web服务器去启动web服务，有利于在开发阶段实现所见即所得；2、介绍了一个 API 叫 watch，这个任务可以去监视一个文件路径的通配符，根据这个文件监视到的结果去决定是否要执行一个任务，这是 gulp 提供的 watch；3、在这个过程中可以重新思考哪些任务是在开发阶段需要执行，哪些任务不是必须要执行。

------



### Gulp 案例 - useref 文件引用处理

会自动处理我们HTML中的这些构建注释，就是自动将开始标签和结束标签中间引入的这些文件最终打包到一个文件当中，那这个文件的路径就是 assets/styles/ventor.css ，如果说你引入了多个css的话，它可以**<u>把这些文件都合并到一块</u>**，这个插件用起来也非常强大。此外可以在这个过程中自动对这些文件做压缩，相对其他方式要更为完善些，因为这个过程能把剩下的压缩、合并等所以事情统统都完成。`yarn add gulp-useref --dev`，useref的意思是引用关系。

此时我们要找的不是src下面的HTML，而是dist下面的HTML，因为在src下的HTML它是模板，模板里面做useref是没有意义的，只有当文件都生成过后再去做才有意义。创建的读取流 pipe 到useref这个插件，这个插件会被自动加载进来，创建一个转换流，会自动把我们刚刚的代码中的构建注释去做对应的转换，这个转换需要指定一个参数叫searchPath，因为你做这个文件合并，那肯定先得找到这些文件，找这个文件就涉及到哪个目录下找。如main.css就得去dist目录下找，那node_modules的就要去项目根目录下找，所以需要指定两个。

```js
// 这个任务名就叫useref
const useref = () => {
    return src('dist/*.html', {base: 'dist'}) // 指定一个base目录，因为它所在的目录就是dist目录，只不过为了统一都指定了
    	.pipe(plugins.useref({ searchPath: [ 'dist', '.' ] }))
    	.pipe(dest('dist'))
    // 它会自动把dist下面的html拿出来去做useref操作，操作完后放回dist
}
module.exports = {
    clean,
    compile,
    build,
    develop,
    useref
}
```

执行完后你去dist下的html会发现，他把全部构建注释都去掉了，把构建注释里面包含的内容最终合并到一个文件中，包括脚本文件合并到一个js里，把JQ、bootstrap和其他库都合并到一个文件中。

------



光这样使用还不行，这里useref在这个过程中自动修改了html，并且帮你把html里面的依赖的文件创建了一些新的文件生成到dist中，那这个过程它会去在读取流中去创建一些新的文件，我们可以对这些新的文件做一些操作。如新创建的js文件我们希望能对他做一些压缩，创建的css也希望能对他做一个压缩，可以单独加一些插件。

### Gulp 案例 - 文件压缩

有了useref后就自动帮我们把对应依赖的文件全部拿过来，但还是需要对生成的文件进行压缩操作过程。我们压缩的文件有3种：HTML、JS、CSS。那HTML是就是直接通过src读取流创建出来的，JS和CSS是 useref 在工作的过程中创建出来的，所以我们在这个管道接着往下去走的时候，此处会有3种文件类型。那这3种文件类型我们需要分别去做不同的压缩工作，我们需要去为他们**<u>安装不同的压缩插件</u>**（`yarn add gulp-htmlmin gulp-uglify gulp-clean-css --dev`），安装完还有问题，在之前的构建任务中每一次我们读取流当中都是同类型的文件，我们对他做相同的操作是合理的，但是我们这个时候读取流中有3种类型的文件，我们需要去分别对他们做不同的操作。

这个时候需要一个额外的操作，就是判断一下这个读取流当中是什么文件，就做什么操作，（`yarn add gulp-if --dev`），然后回来使用它了。pipe 到 plugins.if，这个if会自动创建转换流，只不过在这个转换流内部会根据 if 中给它指定的条件去决定是否要去执行具体的转换流，第一个参数就是自动匹配我们文件读取流当中的文件路径，就意味着路径一旦要是匹配 .js 结尾的话，他就会执行我们后面指定的转换流，那第二个参数就是指定我们需要工作的转换流。搞定后就执行useref任务。

```js
const useref = () => {
    return src('dist/*.html', {base: 'dist'})
    	.pipe(plugins.useref({ searchPath: [ 'dist', '.' ] }))
    	// html js css
    	.pipe(plugins.if(/\.js$/, plugins.uglify()))  // 是否以.js结尾。
    	.pipe(plugins.if(/\.css$/, plugins.cleanCss()))
    	.pipe(plugins.if(/\.html/, plugins.htmlmin()))
    	.pipe(dest('dist'))
}
```

这里因为我们上一节第一次执行 useref 的时候已结把dist下面的html的构建注释清掉了，你再去构建的时候它里面没有那些构建注释，那useref 就不会产生 js文件，所以就没有压缩的转换。所以这里要先执行 compile 然后再去执行 useref，就OK了。



因为我们在这实际上读取流是dist然后我们又把文件写入到写入流中，此时会产生文件读写冲突，如果读写没有分离开可能会导致写不进去的情况。我们就把 dist 最终转换过后的结果不放在 dist 目录下咯，此时style、js就正常压缩完了。

完成之后发现，html文件还没有压缩需要单独处理，因为htmlmin默认只是去压缩你属性中的空白字符，但是针对其他如换行符等默认不帮你删除，要想删可以指定选项 `collapseWhitespace: true` 折叠掉我们的空白字符，就会压缩你的html里的空白字符和换行符。再执行useref，此时HTML的的代码就已经被压缩掉了。但是他html里写的CSS和JS默认没有压缩，也可以指定选项压缩 ，搞定就全部压完了。htmlmin 还有一些其他的参数如 remove 把全部注释删掉，还有空属性删除，那些可以看文档看看使用。

```js
const useref = () => {
    return src('dist/*.html', {base: 'dist'})
    	.pipe(plugins.useref({ searchPath: [ 'dist', '.' ] }))
    	// html js css
    	.pipe(plugins.if(/\.js$/, plugins.uglify()))  // 是否以.js结尾。
    	.pipe(plugins.if(/\.css$/, plugins.cleanCss()))
    	.pipe(plugins.if(/\.html$/, plugins.htmlmin({
        	collapseWhitespace: true,
        	minifyCSS: true,
        	minifyJS: true
    	})))
    	.pipe(dest('release'))
}
```

------



### Gulp 案例 - 重新规划构建过程

useref 打破了我们构建目录结构，因为我们之前约定的是我们在开发阶段的代码是放在 src 目录下，在编译完打包上线的目录是 dist，但是刚刚在 dist 读出来再往 dist 中写产生了冲突，那我们不得已把它放到另外一个目录，其实这个时候我们真正上线的是 release 这个目录中的文件，而release中没有图片和字体文件，所以这个目录结构被他打破了，需要重新规整一下！！！

修改一下：clean可以再加一个需要清空的目录 `['dist', 'temp']`，然后让style、script、page都 `pipe(dest('temp'))`到临时目录，图片、字体和 extra 并不需要放在临时目录，因为这3个转换的过程只是在 build 的时候去做，意味着上线前构建的时候做，开发阶段不需要转换，不需要放到temp下，只有那些被 useref 影响的才需要修改。然后就是bs.init 里要改 baseDir 第一个参数 'dist' 改成 'temp' ，就不能从 dist 里拿文件了，就temp找不到去src找不到去public，dist 是最终构建需要上线打包的目录，所以这里改成 temp。然后就是 useref 里从 temp 去取文件（src方法、base里也改成temp、searchPath也一样），把最终结果放到 dist里(dest方法)，差不多就OK了。



------



### Gulp 案例 - 补充

巴拉巴拉一堆，最终只导出3个任务（clean、build、develop）。还可以把这3个任务都放到你的 package.json 去定义到 scripts 中，这样可以更容易让别人理解一点，因为一般来讲的话去打开一个项目首先去想要了解它这个项目的构建过程的话，一般会从 scripts 里面去着手，那你把它放到 scripts 中，第一个用起来方便第二更容易看明白，所以在里面就加上 scripts ，然后 scripts 中有这3个任务。就相当于通过 npm scripts 把我们这些任务都给他包起来。

这里需要注意的是，我们在NPMScripts中会自动去找这个你所执行的命令在node_modules中的可执行命令文件，所以说我们不用再通过 yarn 去启动它，当然你使用npm的话也是不用再去使用什么 npm run 的方式了。那后续就可以直接 yarn clean 就可以了。

```json
{
    "scripts": {
        "clean": "gulp clean",
        "build": "gulp build",
        "develop": "gulp develop"
    }
}
```



除此之外就是在 .gitignore 中需要去忽略一下生成的这些目录，首先 dist 目录首先要忽略掉，然后 temp 目录，基本上OK了。

第二个问题是开发过程中创建的构建的自动化工作流，这个工作流只要是在相同类型的项目中我们都会重复被使用到，对于常见的开发者来讲，他们大部分情况都是把它放到一个代码段当中或者是笔记中记下来，后续用到再粘过来，这种方式可以但不推荐。那么如何提取多个项目中共同的自动化构建过程。



------



## 封装工作流 - 准备

重点考虑一下关于项目中 gulpfile 复用的问题，因为如果说我们涉及到要开发到多个同类型项目，那我们这个自动化构建工作流应该是一样的，就涉及到多个项目中重复去使用这些构建任务，这些构建任务绝大多数情况下都是相同的，就面临我们要去复用相同 gulpfile 问题。重点来看怎么去提取一个可复用的自动化构建工作流，解决方案就是通过我们去创建一个新的模块，去包装一下 gulp，然后把这个自动化构建工作流给它包装进去。因为 gulp 只是自动化构建工作流的一个平台，它不负责帮你提供任何构建任务，你的构建任务需要通过你的 gulpfile 去定义，现在我们有了 gulpfile，也有了 gulp，把二者通过一个模块结合到一起，过后呢在以后同类型项目中就使用我们这个模块去提供自动化构建的工作流就好了。

具体：创建一个模块，把这个模块发布到 npm 的仓库上，最后我们在我们项目中使用这个模块就可以了。

（接下来这里没有记任何东西）



------



## FIS 

是百度前端团队推出的构建系统，相比于 grunt 和 gulp，FIS核心特点是高度集成，因为他把前端日常开发过程中常见的构建任务和调试任务，都集成在内部，那开发者就可以通过简单的配置文件方式去配置构建过程需要完成的工作。即不像他们需要去定义一些任务，FIS中有内置的任务，这些内置的任务会根据开发者的配置自动完成整个构建过程，此外，FIS中还内置了一款用于调试的WEB server可以很方便的调试我们构建结果，这些在 gulp 和 grunt 都需要插件实现。

### FIS 的基本使用

`yarn global add fis3` 

FIS3 默认的构建任务：`fis3 release`，会自动将项目下所有需要被构建的文件自动构建到1个临时的目录中，可以在C盘用户这个文件夹中找到。如果说你要指定这个输出的目录在项目的根目录下，可以通过 -d 的参数去指定这个文件夹的名字（`fis3 release -d output`）。此时在项目根目录下会多出一个output文件夹，构建过后的结果，并没有做任何转换，默认只会将代码中对于资源文件的引用，相对路径转换成绝对路径（前面多了个/），从而实现资源定位。

资源定位是FIS的核心特性，作用是将开发阶段的路径彻底的与部署路径之间关系分离开。

在项目根目录添加一个 fis-config.js文件。通过 fis.match 方法为我们在构建过程中匹配到的一些文件，添加指定的配置，这里匹配到就是JS文件、SCSS和png文件，我们将它 release 过后的结果放在 assets 下面的 $0 ，刀了0指的是当前文件原始的目录结构。这么一来我们输出的资源文件都会出现在 assets 目录下了。

```js
fis.match('*.{js,scss,png}', {
  release: '/assets/$0'
})

// 任意目录下的*.scss
fis.match('**/*.scss', {
  rExt: '.css',
  parser: fis.plugin('node-sass'),
  optimizer: fis.plugin('clean-css')
})

fis.match('**/*.js', {
  parser: fis.plugin('babel-6.x'),
  optimizer: fis.plugin('uglify-js')
})

```

通过 FIS 资源定位的能力可以大大提高代码的可移植性，因为这个时候你不管是部署在哪个后端项目中，它只需要告诉你，你的生成结构是什么，然后你根据生成结构去配置你的 FIS 配置文件就可以了。

------

### FIS 的编译与压缩

`yarn global add fis-parser-node-sass`

 `fis3 release -d output`

 FIS 不用了，但是可以学习它，不是因为某个东西火才学，而是在这些东西里面能收获什么。















